{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/cuitiancheng/ProG/\")\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "from prompt_graph.tasker import NodeTask, GraphTask\n",
    "from prompt_graph.utils import seed_everything\n",
    "from torchsummary import summary\n",
    "from prompt_graph.utils import print_model_parameters\n",
    "from prompt_graph.utils import get_args\n",
    "from prompt_graph.data import load4node, load4graph, split_induced_graphs\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can unzip the Experiment.zip to get the induced_graph file or run to get the induced_graph by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_induced_graph(dataset_name, data, device):\n",
    "\n",
    "    folder_path = \"./Experiment/induced_graph/\" + dataset_name\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    file_path = folder_path + \"/induced_graph_min100_max300.pkl\"\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            print(\"loading induced graph...\")\n",
    "            graphs_list = pickle.load(f)\n",
    "            print(\"Done!!!\")\n",
    "    else:\n",
    "        print(\"Begin split_induced_graphs.\")\n",
    "        split_induced_graphs(\n",
    "            data, folder_path, device, smallest_size=100, largest_size=300\n",
    "        )\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            graphs_list = pickle.load(f)\n",
    "    graphs_list = [graph.to(device) for graph in graphs_list]\n",
    "    return graphs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_args:\n",
    "    downstream_task = \"NodeTask\"  # 根据你的需求设置\n",
    "    dataset_name = \"Cora\"\n",
    "    device = 0\n",
    "    gnn_type = \"GCN\"\n",
    "    prompt_type = \"GPF-plus\"\n",
    "    hid_dim = 128\n",
    "    batch_size = 128\n",
    "    epochs = 1000\n",
    "    shot_num = 1\n",
    "    pre_train_model_path = (\n",
    "        \"./Experiment/pre_trained_model/Cora/Edgepred_Gprompt.GCN.128hidden_dim.pth\"\n",
    "    )\n",
    "    lr = 0.02\n",
    "    decay = 2e-6\n",
    "    num_layer = 2\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.downstream_task == \"NodeTask\":\n",
    "    data, input_dim, output_dim = load4node(args.dataset_name)\n",
    "    print(output_dim)\n",
    "    data = data.to(args.device)\n",
    "    if args.prompt_type in [\"Gprompt\", \"All-in-one\", \"GPF\", \"GPF-plus\"]:\n",
    "        graphs_list = load_induced_graph(args.dataset_name, data, args.device)\n",
    "    else:\n",
    "        graphs_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if args.downstream_task == \"GraphTask\":\n",
    "    input_dim, output_dim, dataset = load4graph(args.dataset_name)\n",
    "\n",
    "if args.downstream_task == \"NodeTask\":\n",
    "    tasker = NodeTask(\n",
    "        pre_train_model_path=args.pre_train_model_path,\n",
    "        dataset_name=args.dataset_name,\n",
    "        num_layer=args.num_layer,\n",
    "        gnn_type=args.gnn_type,\n",
    "        hid_dim=args.hid_dim,\n",
    "        prompt_type=args.prompt_type,\n",
    "        epochs=args.epochs,\n",
    "        shot_num=args.shot_num,\n",
    "        device=args.device,\n",
    "        lr=args.lr,\n",
    "        wd=args.decay,\n",
    "        batch_size=args.batch_size,\n",
    "        data=data,\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        graphs_list=graphs_list,\n",
    "    )\n",
    "\n",
    "if args.downstream_task == \"GraphTask\":\n",
    "    tasker = GraphTask(\n",
    "        pre_train_model_path=args.pre_train_model_path,\n",
    "        dataset_name=args.dataset_name,\n",
    "        num_layer=args.num_layer,\n",
    "        gnn_type=args.gnn_type,\n",
    "        hid_dim=args.hid_dim,\n",
    "        prompt_type=args.prompt_type,\n",
    "        epochs=args.epochs,\n",
    "        shot_num=args.shot_num,\n",
    "        device=args.device,\n",
    "        lr=args.lr,\n",
    "        wd=args.decay,\n",
    "        batch_size=args.batch_size,\n",
    "        dataset=dataset,\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "    )\n",
    "pre_train_type = tasker.pre_train_type\n",
    "\n",
    "\n",
    "_, test_acc, std_test_acc, f1, std_f1, roc, std_roc, _, _ = tasker.run()\n",
    "\n",
    "print(\"Final Accuracy {:.4f}±{:.4f}(std)\".format(test_acc, std_test_acc))\n",
    "print(\"Final F1 {:.4f}±{:.4f}(std)\".format(f1, std_f1))\n",
    "print(\"Final AUROC {:.4f}±{:.4f}(std)\".format(roc, std_roc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
